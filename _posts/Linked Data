Heute ist die letzte Lerneinheit dieses Moduls. Es wird heute um einen Ausblick zu Linked Data gehen, da wir bereits in der letzten Lektion unser Schaubild vervollständigt haben. Ich bin gespannt auf die heutige Sitzung, da solche Ausblicke in der Regel sehr spannend sind.

Ich fand die Lehrevaluation sehr gut, da Herr Lohmeier auf unsere Inputs eingegangen ist und selbst bereits Verbesserungsvorschläge für den nächsten Kurs eingebracht. Den Input, dass dieses Modul in einem vorherigen Semester mehr Sinn gemacht hätte, kann ich nur unterstützen.

Wir widmeten uns ChatGPT und seinen Möglichkeiten. Was ich zum Beispiel nicht wusste, dass Bing auch einen direkten Zugang zu ChatGPT ermöglicht. Wir wurden auf die Medienkompetenz mit dem Umgang solcher AI-Chatbots hingewiesen. Jemand hat bei der Fragensammlung unsere Übungsfrage gestellt: «Honi soit qui mal y pense!» . Es gab leider ein paar falsche Angaben, da merkt man, dass diese Chatbots noch nicht perfekt sind. Überraschend fand ich, dass ein Lerntagebuch als Quelle für Bing angezeigt wurde.

Nachfolgend hatten wir wieder Informationen zu BIBFRAME und Records in Contexts. Diese neuen Standards finde ich sehr spannend. Eine Kontextualisierung von Medien finde ich sinnvoll, da man diese da besser verstehen kann. Meiner Meinung nach sind die vorherigen Standards für Bibliotheken und Archive einfach nicht mehr zeitgemäss Records in Contexts wäre Bestand meiner Bachelor-Thesis gewesen, wenn ich sie nicht verschoben hätte .

Wir hatten noch einen Einblick zu Alma. Dies hat mich sehr interessiert, da ich bisher nur von Alma gehört habe. Ich fand es ein wenig unübersichtlicher als Netbiblio, aber dies kann auch daran liegen, dass ich bereits fünf Jahre damit arbeite. Eventuell muss ich in einer neuen Arbeitsstelle mit Alma arbeiten und in weiteren fünf Jahren würde ich eine andere Aussage treffen. Eine Kommilitonin hat in ihrem Lerntagebuch eine schlechte Erfahrung bei der Registrierung von Alma und Swisscovery.

Anschliessend haben wir uns die Anreicherung von Metadaten mithilfe von OpenRefine und Wikidata gewidmet. Wikidata ist eine Datenbank, welche inspiriert von den verschiedenen Wikipedia-Seiten, das potenzielle Wissen sammeln möchte und für die verschiedenen Sprachseiten zur Verfügung stellen möchte. So können Bilder von Wikidata von anderen Systemen angeknüpft werden. Eine sogenannte Reconciliation würde importierte Daten mit denen von Wikidata vergleichen und Dubletten hervorheben. Spannend war dort, dass beim Beispiel Hermann Hesse ganze acht Treffer gefunden worden. Aber man kann mithilfe des Kontexts und den Informationen bei den Treffern schnell die richtige Zuordnung verknüpfen. Als Tipp wurde noch gesagt, dass man eine zusätzliche Zeile für die Angaben von Wikidata zu ermöglichen, denn bei einer automatischen Zuteilung werden die eingegebenen Daten von den Daten von Wikidata überschrieben.

Die letzte Lerneinheit war meiner Meinung nach sehr spannend. Mir hat es gefallen die verschiedenen Standards oder Zukunftspläne für Linked Data kennenzulernen. Man darf auf die Zukunft von solchen Bibliotheks-und Archivsystemen gespannt sein.
